# Hugging Face token for downloading models
HF_TOKEN=your_token_here

# Server configuration
HOST=0.0.0.0
PORT=8000
WORKERS=1

# Model configuration
DEFAULT_MODEL=llama-3.2-3b
MAX_INPUT_LENGTH=4096
MAX_NEW_TOKENS=2048

# Frontend configuration
NEXT_PUBLIC_API_URL=http://localhost:8000
