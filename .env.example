# Hugging Face token for downloading models
# Get your token from: https://huggingface.co/settings/tokens
# Required scope: read
HUGGING_FACE_HUB_TOKEN=your_token_here

# Server configuration
# Host to bind the server to (default: 0.0.0.0 for all interfaces)
HOST=0.0.0.0
# Port for the backend FastAPI server
PORT=8000
# Number of worker processes
WORKERS=1

# Model configuration
# Default model to load at startup (must match a key in config/models.py)
DEFAULT_MODEL=llama-3.2-3b
# Maximum input length in tokens
MAX_INPUT_LENGTH=4096

# Logging configuration
# Valid levels: DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_LEVEL=INFO
# Whether to output logs in JSON format
JSON_LOGGING=true
# Directory for log files (relative to project root)
LOG_DIR=logs
